{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction in Condmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:39:08.250631Z",
     "iopub.status.busy": "2020-08-06T13:39:08.250328Z",
     "iopub.status.idle": "2020-08-06T13:39:09.433040Z",
     "shell.execute_reply": "2020-08-06T13:39:09.432399Z",
     "shell.execute_reply.started": "2020-08-06T13:39:08.250601Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import math\n",
    "from typing import List, Any, Dict, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Typing\n",
    "Author = int\n",
    "Papers = List[Tuple[List[Author], datetime]]\n",
    "NodePair = Tuple[Author, Author]\n",
    "Edge = List[Tuple[Author, Author, Dict[str, datetime]]]\n",
    "\n",
    "folder = '/local/bruingjde/complexnetworks2020-experiment/temp/b1n/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:40:32.658084Z",
     "iopub.status.busy": "2020-08-06T13:40:32.657641Z",
     "iopub.status.idle": "2020-08-06T13:40:32.682742Z",
     "shell.execute_reply": "2020-08-06T13:40:32.681758Z",
     "shell.execute_reply.started": "2020-08-06T13:40:32.658043Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_papers(filepath: str = \"src/cond-mat.hg2\") -> Papers:\n",
    "  \"\"\"Read collaboration data in filepath and return all papers.\"\"\"\n",
    "  \n",
    "  papers = list()\n",
    "  # Get number of rows to read for the vertices.\n",
    "  with open(filepath) as file:\n",
    "    no_rows = int(file.readline().split(' ')[1])\n",
    " \n",
    "  with open(filepath) as file:\n",
    "    for paper in file.readlines()[no_rows+2:]:\n",
    "      # Each line has the following format: epoch no_authors [ u v (w ...) ]\n",
    "      epoch = datetime.fromtimestamp(int(paper.split(' ')[0]))\n",
    "          \n",
    "      no_authors = int(paper.split(' ')[1])\n",
    "      index1 = paper.find('[')+2\n",
    "      index2 = paper.find(']')-1\n",
    "\n",
    "      authors = [int(auth) for auth in paper[index1:index2].split(' ')]\n",
    "      assert no_authors == len(authors)\n",
    "      \n",
    "      papers.append((authors, epoch))\n",
    "  return papers\n",
    "def _filter_edgelist(edges: List[Edge], start, stop) -> List[Edge]: \n",
    "  \"\"\"Filter edgelist.  If start/ stop is float, start/stop from the fraction of total edges. If datetime, this is used.\"\"\" \n",
    "  no_edges = len(edges)\n",
    "  if start is None: start=0\n",
    "  if stop is None: stop=1\n",
    "  if type(start) is float or start == 0:\n",
    "    start_index = int(start*no_edges)\n",
    "    start = edges[start_index][2]['date']\n",
    "  if type(stop) is float or stop == 1:\n",
    "    stop_index = math.floor(stop*no_edges)-1\n",
    "    stop = edges[stop_index][2]['date']\n",
    "  return [edge for edge in edges if edge[2]['date'] >= start and edge[2]['date'] <= stop]\n",
    "def get_edgelist(*, start=None, stop=None) -> List[Edge]:\n",
    "  \"\"\"Return E_[t_1, t_2].\"\"\"\n",
    "  papers = _get_papers()\n",
    "  edges = [\n",
    "    (u, v, dict(date=date)) if u<v else (v, u, dict(date=date))\n",
    "    for authors, date in papers\n",
    "    for u, v in itertools.combinations(authors, 2)\n",
    "  ]\n",
    "  return _filter_edgelist(edges, start, stop)\n",
    "def giant_component(graph: nx.Graph) -> nx.Graph: return graph.subgraph(max(nx.connected_components(graph), key=len)).copy()\n",
    "def get_graph(edgelist: List[Edge]) -> nx.Graph:\n",
    "  \"\"\"Add edge to graph. Contains edge attribute weight.\"\"\"\n",
    "  g = nx.Graph()\n",
    "  \n",
    "  for u, v, _ in edgelist:\n",
    "    weight = g[u][v][\"weight\"]+1 if g.has_edge(u,v) else 1\n",
    "    g.add_edge(u, v, weight=weight)\n",
    "  \n",
    "  return g\n",
    "def report(graph:nx.Graph, probes: Tuple[Author, Author]):\n",
    "  n = len(probes)\n",
    "  print(f\"Number of probes: {n}\")\n",
    "  a = sum([graph.has_edge(u, v) for u, v in probes])\n",
    "  print(f\"- already edge: {a} ({a/n:.0%})\")\n",
    "  non_edges = set(nx.non_edges(graph))\n",
    "  ne = sum([np in non_edges for np in probes])\n",
    "  print(f\"- both nodes in graph: {ne} ({ne/n:.0%})\")\n",
    "  ng = sum([not (graph.has_node(u) and graph.has_node(v)) for u, v in probes])\n",
    "  print(f\"- not in graph: {ng} ({ng/n:.0%})\")\n",
    "def get_distances(graph: nx.Graph, cutoff: int = None) -> (List[NodePair], List[int]):\n",
    "  \"\"\"\n",
    "  Get all non-edges using BFS. When cutoff provided, consider only node pairs with at most this distance.\n",
    "  Returns:\n",
    "  - nodepairs: tuple containing all nodepairs\n",
    "  - distances: tuple containing all distances\n",
    "  \"\"\"\n",
    "  return zip(\n",
    "    *[\n",
    "      [(u, v), distance]\n",
    "      for u, (nbs_u, _) in tqdm(nx.all_pairs_dijkstra(graph, cutoff, weight=None), total=len(graph), desc=\"get_distances\")\n",
    "      for v, distance in nbs_u.items() if distance > 1 and (cutoff is None or distance <= cutoff) \n",
    "    ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Choose here the parameters on how you want to define the learn and assessing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:40:33.060471Z",
     "iopub.status.busy": "2020-08-06T13:40:33.060296Z",
     "iopub.status.idle": "2020-08-06T13:40:34.732048Z",
     "shell.execute_reply": "2020-08-06T13:40:34.730808Z",
     "shell.execute_reply.started": "2020-08-06T13:40:33.060450Z"
    }
   },
   "outputs": [],
   "source": [
    "g_train_matured = giant_component(get_graph(get_edgelist(stop=datetime(1999, 12, 31))))\n",
    "uv_train_probe = {(u, v) for u, v, _ in get_edgelist(start=datetime(2000, 1, 1), stop=datetime(2000, 6, 30))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:40:36.379081Z",
     "iopub.status.busy": "2020-08-06T13:40:36.378603Z",
     "iopub.status.idle": "2020-08-06T13:41:17.596786Z",
     "shell.execute_reply": "2020-08-06T13:41:17.595155Z",
     "shell.execute_reply.started": "2020-08-06T13:40:36.379038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of probes: 10255\n",
      "- already edge: 3173 (31%)\n",
      "- both nodes in graph: 1900 (19%)\n",
      "- not in graph: 5182 (51%)\n"
     ]
    }
   ],
   "source": [
    "report(graph=g_train_matured, probes=uv_train_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:41:17.599569Z",
     "iopub.status.busy": "2020-08-06T13:41:17.599308Z",
     "iopub.status.idle": "2020-08-06T13:41:19.206277Z",
     "shell.execute_reply": "2020-08-06T13:41:19.205483Z",
     "shell.execute_reply.started": "2020-08-06T13:41:17.599538Z"
    }
   },
   "outputs": [],
   "source": [
    "g_test_matured = giant_component(get_graph(get_edgelist(stop=datetime(2000, 6, 30))))\n",
    "uv_test_probe = {(u, v) for u, v, _ in get_edgelist(start=datetime(2000, 7, 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:41:19.207553Z",
     "iopub.status.busy": "2020-08-06T13:41:19.207375Z",
     "iopub.status.idle": "2020-08-06T13:42:11.378507Z",
     "shell.execute_reply": "2020-08-06T13:42:11.377722Z",
     "shell.execute_reply.started": "2020-08-06T13:41:19.207528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of probes: 11823\n",
      "- already edge: 3589 (30%)\n",
      "- both nodes in graph: 2518 (21%)\n",
      "- not in graph: 5715 (48%)\n"
     ]
    }
   ],
   "source": [
    "report(graph=g_test_matured, probes=uv_test_probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-06T13:45:11.333312Z",
     "iopub.status.busy": "2020-08-06T13:45:11.332789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_distances:   9%|â–‰         | 1062/11723 [01:45<14:50, 11.98it/s]  "
     ]
    }
   ],
   "source": [
    "nodepairs_train, distances_train = get_distances(g_train_matured)\n",
    "targets_train = [nodepair in uv_assessing for nodepairs_train in tqdm(nodepairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{sum(targets_train) / len(nodepairs_train):e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(targets_train, f'{folder}train/targets.pkl')\n",
    "joblib.dump(nodepairs_train, f'{folder}train/nodepairs.pkl')\n",
    "joblib.dump(distances_train, f'{folder}train/distances.pkl')\n",
    "joblib.dump(g_learn_train, f'{folder}train/graph.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodepairs_test, distances_test = get_distances(g_test_matured)\n",
    "targets_test = [nodepair in uv_assessing for nodepairs_test in tqdm(nodepairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{sum(targets_test) / len(nodepairs_test):e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(targets_test, f'{folder}test/targets.pkl')\n",
    "joblib.dump(nodepairs_test, f'{folder}test/nodepairs.pkl')\n",
    "joblib.dump(distances_test, f'{folder}test/distances.pkl')\n",
    "joblib.dump(g_learn_test, f'{folder}test/graph.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
