{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction in Condmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:43:26.225727Z",
     "iopub.status.busy": "2020-08-13T13:43:26.225518Z",
     "iopub.status.idle": "2020-08-13T13:43:27.305436Z",
     "shell.execute_reply": "2020-08-13T13:43:27.304703Z",
     "shell.execute_reply.started": "2020-08-13T13:43:26.225702Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "from typing import List, Any, Dict, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Typing\n",
    "NodePair = Tuple[int, int]\n",
    "Edge = List[Tuple[int, int, Dict['date', datetime.datetime]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:45:49.077269Z",
     "iopub.status.busy": "2020-08-13T13:45:49.077061Z",
     "iopub.status.idle": "2020-08-13T13:45:49.091426Z",
     "shell.execute_reply": "2020-08-13T13:45:49.090821Z",
     "shell.execute_reply.started": "2020-08-13T13:45:49.077247Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_edges(file: str, sep=' ') -> pd.DataFrame:\n",
    "  d = pd.read_csv(file, sep, skiprows=1, names=['source', 'target', 'weight', 'date'])\n",
    "  d['date'] = d['date'].apply(datetime.datetime.fromtimestamp)\n",
    "  d.sort_values(by='date', inplace=True)\n",
    "  return d.loc[:, ['source', 'target', 'date']]\n",
    "def filter_edgelist(edges: pd.DataFrame, start=0, stop=1, verbose=True) -> pd.DataFrame: \n",
    "  \"\"\"Filter edgelist.  If start/ stop is float, start/stop from the fraction of total edges. If datetime, this is used.\"\"\" \n",
    "  no_edges = len(edges)\n",
    "  if start != 0:\n",
    "    if type(start) is float:\n",
    "      assert 0 < start < 1\n",
    "      start = int(start*no_edges)\n",
    "    if type(start) is int: start = edges.iloc[start]['date']\n",
    "    start = start + datetime.timedelta(seconds=1)\n",
    "  else: start = edges['date'].min()\n",
    "  if verbose: print(start)\n",
    "  \n",
    "  if stop != 1:\n",
    "    if type(stop) is float:\n",
    "      assert 0 < stop < 1\n",
    "      stop = math.floor(stop*no_edges)-1\n",
    "    if type(stop) is int: stop = edges.iloc[stop]['date']\n",
    "  else: stop = edges['date'].max()\n",
    "  if verbose: print(stop)\n",
    "  \n",
    "  mask = (edges['date'] >= start) & (edges['date'] <= stop)\n",
    "  if verbose: \n",
    "    no_selected_edges = sum(mask)\n",
    "    print(f'{no_selected_edges=}, ({no_selected_edges/len(edges):.1e})')\n",
    "\n",
    "  return edges.loc[mask]\n",
    "def convert_to_set(edges: pd.DataFrame) -> List[NodePair]: return {edge for edge in edges.loc[:, ['source', 'target']].itertuples(index=False, name=None)}\n",
    "def get_graph(edgelist: pd.DataFrame) -> nx.Graph:\n",
    "  \"\"\"Add edge to graph. Contains edge attribute weight.\"\"\"\n",
    "  g = nx.Graph()\n",
    "  \n",
    "  for u, v, _ in edgelist.itertuples(index=False, name=None):\n",
    "    weight = g[u][v][\"weight\"]+1 if g.has_edge(u,v) else 1\n",
    "    g.add_edge(u, v, weight=weight)\n",
    "  \n",
    "  return g\n",
    "def giant_component(graph: nx.Graph) -> nx.Graph: return graph.subgraph(max(nx.connected_components(graph), key=len)).copy()\n",
    "def report(graph:nx.Graph, probes: Tuple[int, int]):\n",
    "  n = len(probes)\n",
    "  print(f\"Number of probes: {n}\")\n",
    "  a = sum([graph.has_edge(u, v) for u, v in probes])\n",
    "  print(f\"- already edge: {a} ({a/n:.0%})\")\n",
    "  non_edges = set(nx.non_edges(graph))\n",
    "  ne = sum([np in non_edges for np in probes])\n",
    "  print(f\"- both nodes in graph: {ne} ({ne/n:.0%})\")\n",
    "  ng = sum([not (graph.has_node(u) and graph.has_node(v)) for u, v in probes])\n",
    "  print(f\"- not in graph: {ng} ({ng/n:.0%})\")\n",
    "def get_distances(graph: nx.Graph, cutoff: int = None) -> (List[NodePair], List[int]):\n",
    "  \"\"\"\n",
    "  Get all non-edges using BFS. When cutoff provided, consider only node pairs with at most this distance.\n",
    "  Returns:\n",
    "  - nodepairs: tuple containing all nodepairs\n",
    "  - distances: tuple containing all distances\n",
    "  \"\"\"\n",
    "  return zip(\n",
    "    *[\n",
    "      ((u, v), distance)\n",
    "      for u, (nbs_u, _) in tqdm(nx.all_pairs_dijkstra(graph, cutoff, weight=None), total=len(graph), desc=\"get_distances\")\n",
    "      for v, distance in nbs_u.items() if distance > 1 and (cutoff is None or distance <= cutoff) \n",
    "    ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:45:49.217964Z",
     "iopub.status.busy": "2020-08-13T13:45:49.217780Z",
     "iopub.status.idle": "2020-08-13T13:45:50.002257Z",
     "shell.execute_reply": "2020-08-13T13:45:50.001489Z",
     "shell.execute_reply.started": "2020-08-13T13:45:49.217943Z"
    }
   },
   "outputs": [],
   "source": [
    "edges = read_edges('out.sx-askubuntu', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:45:51.389853Z",
     "iopub.status.busy": "2020-08-13T13:45:51.389668Z",
     "iopub.status.idle": "2020-08-13T13:45:51.393368Z",
     "shell.execute_reply": "2020-08-13T13:45:51.392751Z",
     "shell.execute_reply.started": "2020-08-13T13:45:51.389832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 9.6e+05\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of edges: {len(edges):.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:45:59.986907Z",
     "iopub.status.busy": "2020-08-13T13:45:59.986692Z",
     "iopub.status.idle": "2020-08-13T13:46:00.087862Z",
     "shell.execute_reply": "2020-08-13T13:46:00.087173Z",
     "shell.execute_reply.started": "2020-08-13T13:45:59.986886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-08 17:20:07\n",
      "2011-05-02 02:56:55\n",
      "no_selected_edges=50001, (5.2e-02)\n"
     ]
    }
   ],
   "source": [
    "edges_mature = filter_edgelist(edges, stop=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:46:01.040938Z",
     "iopub.status.busy": "2020-08-13T13:46:01.040757Z",
     "iopub.status.idle": "2020-08-13T13:46:06.122503Z",
     "shell.execute_reply": "2020-08-13T13:46:06.121795Z",
     "shell.execute_reply.started": "2020-08-13T13:46:01.040917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-05-02 02:56:56\n",
      "2011-07-19 07:09:40\n",
      "no_selected_edges=20000, (2.1e-02)\n"
     ]
    }
   ],
   "source": [
    "edges_probe = filter_edgelist(edges, start=50000, stop=70000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Choose here the parameters on how you want to define the learn and assessing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:46:12.183064Z",
     "iopub.status.busy": "2020-08-13T13:46:12.182828Z",
     "iopub.status.idle": "2020-08-13T13:46:12.645274Z",
     "shell.execute_reply": "2020-08-13T13:46:12.644505Z",
     "shell.execute_reply.started": "2020-08-13T13:46:12.183041Z"
    }
   },
   "outputs": [],
   "source": [
    "g_learn = giant_component(get_graph(edges_mature))\n",
    "uv_assessing = convert_to_set(edges_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:46:23.591569Z",
     "iopub.status.busy": "2020-08-13T13:46:23.591359Z",
     "iopub.status.idle": "2020-08-13T13:46:24.212809Z",
     "shell.execute_reply": "2020-08-13T13:46:24.212228Z",
     "shell.execute_reply.started": "2020-08-13T13:46:23.591547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random/probes.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(g_learn, 'random/graph.pkl')\n",
    "joblib.dump(uv_assessing, f'random/probes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:46:26.835772Z",
     "iopub.status.busy": "2020-08-13T13:46:26.835572Z",
     "iopub.status.idle": "2020-08-13T13:46:40.297534Z",
     "shell.execute_reply": "2020-08-13T13:46:40.296634Z",
     "shell.execute_reply.started": "2020-08-13T13:46:26.835750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of probes: 13697\n",
      "- already edge: 1067 (8%)\n",
      "- both nodes in graph: 1918 (14%)\n",
      "- not in graph: 8671 (63%)\n"
     ]
    }
   ],
   "source": [
    "report(graph=g_learn, probes=uv_assessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T07:25:12.679864Z",
     "iopub.status.busy": "2020-08-05T07:25:12.679699Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "targets = joblib.load(f'{folder}all/targets.pkl')\n",
    "nodepairs = joblib.load(f'{folder}all/nodepairs.pkl')\n",
    "distances = joblib.load(f'{folder}all/distances.pkl')\n",
    "g_learn = joblib.load(f'{folder}all/graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:46:40.299481Z",
     "iopub.status.busy": "2020-08-13T13:46:40.299267Z",
     "iopub.status.idle": "2020-08-13T13:47:15.514823Z",
     "shell.execute_reply": "2020-08-13T13:47:15.514099Z",
     "shell.execute_reply.started": "2020-08-13T13:46:40.299451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_distances: 100%|██████████| 4953/4953 [00:32<00:00, 150.70it/s]\n"
     ]
    }
   ],
   "source": [
    "nodepairs, _ = get_distances(g_learn, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:47:15.516353Z",
     "iopub.status.busy": "2020-08-13T13:47:15.516162Z",
     "iopub.status.idle": "2020-08-13T13:47:16.372871Z",
     "shell.execute_reply": "2020-08-13T13:47:16.372159Z",
     "shell.execute_reply.started": "2020-08-13T13:47:15.516328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2483166/2483166 [00:00<00:00, 2916083.30it/s]\n"
     ]
    }
   ],
   "source": [
    "targets = [nodepair in uv_assessing for nodepair in tqdm(nodepairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:47:16.373920Z",
     "iopub.status.busy": "2020-08-13T13:47:16.373777Z",
     "iopub.status.idle": "2020-08-13T13:47:47.519117Z",
     "shell.execute_reply": "2020-08-13T13:47:47.518390Z",
     "shell.execute_reply.started": "2020-08-13T13:47:16.373901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random/2/targets.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nodepairs, 'random/2/nodepairs.pkl', protocol=5)\n",
    "joblib.dump(targets, 'random/2/targets.pkl', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nodepairs = np.array(nodepairs)\n",
    "distances = np.array(distances)\n",
    "targets = np.array(targets)\n",
    "for select_distance in [3]:\n",
    "  print(select_distance)\n",
    "  filter_indices = (distances == select_distance)\n",
    "  nodepairs[filter_indices].dump(f'{folder}{select_distance}/nodepairs.pkl')\n",
    "  distances[filter_indices].dump(f'{folder}{select_distance}/distances.pkl')\n",
    "  targets[filter_indices].dump(f'{folder}{select_distance}/targets.pkl')\n",
    "  joblib.dump(g_learn, f'{folder}{select_distance}/graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T13:47:50.521160Z",
     "iopub.status.busy": "2020-08-13T13:47:50.521008Z",
     "iopub.status.idle": "2020-08-13T13:47:53.967549Z",
     "shell.execute_reply": "2020-08-13T13:47:53.966723Z",
     "shell.execute_reply.started": "2020-08-13T13:47:50.521136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.936173e-04\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(targets) / len(nodepairs):e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(distances=distances, targets=targets))\n",
    "df = df.groupby('distances')['targets'].agg(['size', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['size'], fill='tozeroy', name='# Nodepairs'))\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['sum'], fill='tozeroy', name='# Positives'))\n",
    "fig.update_layout(xaxis=dict(tickmode='linear', tick0=2, dtick=1), yaxis_type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['size'].cumsum(), fill='tozeroy', name='# Nodepairs'))\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['sum'].cumsum(), fill='tozeroy', name='# Positives'))\n",
    "fig.update_layout(xaxis=dict(tickmode='linear', tick0=2, dtick=1), yaxis_type=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = joblib.load(\"random/2/features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(df.corr(), x=df.columns, y=df.columns)\n",
    "fig.update_xaxes(side=\"top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot(df):\n",
    "  return sns.pairplot(\n",
    "    df[df['target']].append(df[~df['target']].sample(sum(df['target']))).apply(minmax_scale), \n",
    "    hue='target',\n",
    "    hue_order=[True, False],\n",
    "    palette={True: 'green', False: 'red'},\n",
    "    kind='reg',\n",
    "    diag_kws=dict(bw=.02),\n",
    "    plot_kws=dict(scatter_kws=dict(alpha=.1))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `parameter_optimalization.ipynb`. We choose the following parameters:\n",
    "- `max_depth = 1`\n",
    "- `tree_method = 'hist'`\n",
    "- `no feature scaling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T20:03:42.312674Z",
     "iopub.status.busy": "2020-08-13T20:03:42.312517Z",
     "iopub.status.idle": "2020-08-13T20:03:42.323958Z",
     "shell.execute_reply": "2020-08-13T20:03:42.323389Z",
     "shell.execute_reply.started": "2020-08-13T20:03:42.312655Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridsearch(df: pd.DataFrame, random_state=1, also_random=True, max_depth=[1, 2]) -> pd.DataFrame:\n",
    "  X = df.drop(columns='target').values\n",
    "  y = df['target'].values\n",
    "  \n",
    "  param_grid=dict(max_depth=max_depth, scale_pos_weight=[sum(~y)/sum(y), 1])\n",
    "  \n",
    "  X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3, random_state=random_state)\n",
    "  clf = XGBClassifier(random_state=random_state, tree_method='hist', n_jobs=6)\n",
    "  gridsearch = GridSearchCV(\n",
    "    clf, \n",
    "    param_grid=param_grid, \n",
    "    scoring='average_precision', \n",
    "    n_jobs=30,\n",
    "    cv=StratifiedKFold(shuffle=True, random_state=random_state),\n",
    "    return_train_score=True\n",
    "  )\n",
    "  \n",
    "  if also_random: \n",
    "    gridsearch_random = copy.deepcopy(gridsearch)\n",
    "    np.random.seed(random_state)\n",
    "    y_random = copy.deepcopy(y_trainval)\n",
    "    np.random.shuffle(y_random)\n",
    "  \n",
    "  gridsearch.fit(X_trainval, y_trainval)\n",
    "  df_dict = dict(\n",
    "      mean_train=gridsearch.cv_results_['mean_train_score'],\n",
    "      std_train=gridsearch.cv_results_['std_train_score'],\n",
    "      mean_test=gridsearch.cv_results_['mean_test_score'],\n",
    "      std_test=gridsearch.cv_results_['std_test_score'],\n",
    "      test_fold0=gridsearch.cv_results_[f'split0_test_score'],\n",
    "      test_fold1=gridsearch.cv_results_[f'split1_test_score'],\n",
    "      test_fold2=gridsearch.cv_results_[f'split2_test_score'],\n",
    "      test_fold3=gridsearch.cv_results_[f'split3_test_score'],\n",
    "      test_fold4=gridsearch.cv_results_[f'split4_test_score']\n",
    "  )\n",
    "  \n",
    "  if also_random: \n",
    "    gridsearch_random.fit(X_trainval, y_random)\n",
    "    df_dict['mean_train_random']=gridsearch_random.cv_results_['mean_train_score']\n",
    "    df_dict['std_train_random']=gridsearch_random.cv_results_['std_train_score']\n",
    "    df_dict['mean_test_random']=gridsearch_random.cv_results_['mean_test_score']\n",
    "    df_dict['std_test_random']=gridsearch_random.cv_results_['std_test_score']\n",
    "  df = pd.DataFrame(df_dict, index=pd.Index([(d['max_depth'], d['scale_pos_weight'] > 1) for d in gridsearch.cv_results_['params']], name=('max_depth', 'balanced')))\n",
    "  df['diff_train_test'] = (df['mean_test'] - df['mean_train']).abs()\n",
    "  df['rstd_test'] = df['std_test'] / df['mean_test']\n",
    "  if also_random: df['test_over_random'] = df['mean_test'] - df['mean_test_random']\n",
    "  return df.sort_values('mean_test', ascending=False)\n",
    "    \n",
    "def report_performance(df: pd.DataFrame, random_state=1, max_depth=1, tree_method='hist', balanced=True, n_jobs=128):\n",
    "  X = df.drop(columns='target').values\n",
    "  y = df['target'].values\n",
    "  X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3, random_state=random_state)\n",
    "  clf = XGBClassifier(max_depth=max_depth, n_jobs=128, tree_method=tree_method, scale_pos_weight=sum(~y)/sum(y) if balanced else 1 , random_state=random_state)\n",
    "  clf.fit(X_trainval, y_trainval)\n",
    "  y_pred = clf.predict_proba(X_test)[:,1]\n",
    "  return average_precision_score(y_test, y_pred), roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'temp/a1/2/features.pkl')\n",
    "X = df.drop(columns='target').values\n",
    "y = df['target'].values\n",
    "\n",
    "param_grid=dict(max_depth=[1, 2], scale_pos_weight=[sum(~y)/sum(y), 1])\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "clf = XGBClassifier(random_state=1, tree_method='hist', n_jobs=6)\n",
    "gridsearch = GridSearchCV(\n",
    "  clf, \n",
    "  param_grid=param_grid, \n",
    "  scoring='average_precision', \n",
    "  n_jobs=30,\n",
    "  cv=StratifiedKFold(shuffle=True, random_state=1),\n",
    "  return_train_score=True\n",
    ")\n",
    "gridsearch.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T20:03:45.064399Z",
     "iopub.status.busy": "2020-08-13T20:03:45.064250Z",
     "iopub.status.idle": "2020-08-13T20:04:23.665194Z",
     "shell.execute_reply": "2020-08-13T20:04:23.664025Z",
     "shell.execute_reply.started": "2020-08-13T20:03:45.064381Z"
    }
   },
   "outputs": [],
   "source": [
    "hps2 = gridsearch(pd.read_pickle(f'random/2/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T20:06:13.516061Z",
     "iopub.status.busy": "2020-08-13T20:06:13.515741Z",
     "iopub.status.idle": "2020-08-13T20:06:13.530836Z",
     "shell.execute_reply": "2020-08-13T20:06:13.530134Z",
     "shell.execute_reply.started": "2020-08-13T20:06:13.516035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_test</th>\n",
       "      <th>diff_train_test</th>\n",
       "      <th>rstd_test</th>\n",
       "      <th>test_over_random</th>\n",
       "      <th>test_fold0</th>\n",
       "      <th>test_fold1</th>\n",
       "      <th>test_fold2</th>\n",
       "      <th>test_fold3</th>\n",
       "      <th>test_fold4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th>balanced</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>False</th>\n",
       "      <td>0.041473</td>\n",
       "      <td>0.346244</td>\n",
       "      <td>0.120017</td>\n",
       "      <td>0.040560</td>\n",
       "      <td>0.046468</td>\n",
       "      <td>0.043193</td>\n",
       "      <td>0.046345</td>\n",
       "      <td>0.034082</td>\n",
       "      <td>0.037276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.029424</td>\n",
       "      <td>0.038861</td>\n",
       "      <td>0.047644</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>0.029342</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.028590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>False</th>\n",
       "      <td>0.019488</td>\n",
       "      <td>0.050299</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.018554</td>\n",
       "      <td>0.018621</td>\n",
       "      <td>0.022406</td>\n",
       "      <td>0.019953</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.025251</td>\n",
       "      <td>0.107087</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.018357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean_test  diff_train_test  rstd_test  test_over_random  \\\n",
       "max_depth balanced                                                            \n",
       "2         False      0.041473         0.346244   0.120017          0.040560   \n",
       "          True       0.029424         0.038861   0.047644          0.028534   \n",
       "1         False      0.019488         0.050299   0.094515          0.018554   \n",
       "          True       0.016752         0.025251   0.107087          0.015825   \n",
       "\n",
       "                    test_fold0  test_fold1  test_fold2  test_fold3  test_fold4  \n",
       "max_depth balanced                                                              \n",
       "2         False       0.046468    0.043193    0.046345    0.034082    0.037276  \n",
       "          True        0.029342    0.028542    0.032157    0.028488    0.028590  \n",
       "1         False       0.018621    0.022406    0.019953    0.016761    0.019701  \n",
       "          True        0.017591    0.017891    0.016554    0.013365    0.018357  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps2[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3 = gridsearch(pd.read_pickle(f'temp/a1/3/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps4 = gridsearch(pd.read_pickle(f'temp/a1/4/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps4[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T20:06:44.688866Z",
     "iopub.status.busy": "2020-08-13T20:06:44.688552Z",
     "iopub.status.idle": "2020-08-13T20:07:08.178067Z",
     "shell.execute_reply": "2020-08-13T20:07:08.177004Z",
     "shell.execute_reply.started": "2020-08-13T20:06:44.688840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021527575200352297, 0.89612121501075)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_performance(pd.read_pickle(f'random/2/features.pkl'), max_depth=2, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(pd.read_pickle(f'temp/a1/3/features.pkl'), balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(pd.read_pickle(f'temp/a1/4/features.pkl'), balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
