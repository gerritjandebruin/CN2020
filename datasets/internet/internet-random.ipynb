{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction in Condmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T08:14:43.106379Z",
     "iopub.status.busy": "2020-08-30T08:14:43.106140Z",
     "iopub.status.idle": "2020-08-30T08:14:43.112874Z",
     "shell.execute_reply": "2020-08-30T08:14:43.112102Z",
     "shell.execute_reply.started": "2020-08-30T08:14:43.106353Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "from typing import List, Any, Dict, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Typing\n",
    "NodePair = Tuple[int, int]\n",
    "Edge = List[Tuple[int, int, Dict['date', datetime.datetime]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T08:14:43.406144Z",
     "iopub.status.busy": "2020-08-30T08:14:43.405934Z",
     "iopub.status.idle": "2020-08-30T08:14:43.426734Z",
     "shell.execute_reply": "2020-08-30T08:14:43.425992Z",
     "shell.execute_reply.started": "2020-08-30T08:14:43.406119Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_edges(file: str, sep=' ') -> pd.DataFrame:\n",
    "  d = pd.read_csv(file, sep, skiprows=1, names=['source', 'target', 'weight', 'date'])\n",
    "  d['date'] = d['date'].apply(datetime.datetime.fromtimestamp)\n",
    "  d.sort_values(by='date', inplace=True)\n",
    "  return d.loc[:, ['source', 'target', 'date']]\n",
    "def filter_edgelist(edges: pd.DataFrame, start=0, stop=1, verbose=True) -> pd.DataFrame: \n",
    "  \"\"\"Filter edgelist.  If start/ stop is float, start/stop from the fraction of total edges. If datetime, this is used.\"\"\" \n",
    "  no_edges = len(edges)\n",
    "  if start != 0:\n",
    "    if type(start) is float:\n",
    "      assert 0 < start < 1\n",
    "      start = int(start*no_edges)\n",
    "    if type(start) is int: start = edges.iloc[start]['date']\n",
    "    start = start + datetime.timedelta(seconds=1)\n",
    "  else: start = edges['date'].min()\n",
    "  if verbose: print(start)\n",
    "  \n",
    "  if stop != 1:\n",
    "    if type(stop) is float:\n",
    "      assert 0 < stop < 1\n",
    "      stop = math.floor(stop*no_edges)-1\n",
    "    if type(stop) is int: stop = edges.iloc[stop]['date']\n",
    "  else: stop = edges['date'].max()\n",
    "  if verbose: print(stop)\n",
    "  \n",
    "  mask = (edges['date'] >= start) & (edges['date'] <= stop)\n",
    "  if verbose: \n",
    "    no_selected_edges = sum(mask)\n",
    "    print(f'{no_selected_edges=}, ({no_selected_edges/len(edges):.1e})')\n",
    "\n",
    "  return edges.loc[mask]\n",
    "def convert_to_set(edges: pd.DataFrame) -> List[NodePair]: return {edge for edge in edges.loc[:, ['source', 'target']].itertuples(index=False, name=None)}\n",
    "def get_graph(edgelist: pd.DataFrame) -> nx.Graph:\n",
    "  \"\"\"Add edge to graph. Contains edge attribute weight.\"\"\"\n",
    "  g = nx.Graph()\n",
    "  \n",
    "  for u, v, _ in edgelist.itertuples(index=False, name=None):\n",
    "    weight = g[u][v][\"weight\"]+1 if g.has_edge(u,v) else 1\n",
    "    g.add_edge(u, v, weight=weight)\n",
    "  \n",
    "  return g\n",
    "def giant_component(graph: nx.Graph) -> nx.Graph: return graph.subgraph(max(nx.connected_components(graph), key=len)).copy()\n",
    "def report(graph:nx.Graph, probes: Tuple[int, int]):\n",
    "  n = len(probes)\n",
    "  print(f\"Number of probes: {n}\")\n",
    "  a = sum([graph.has_edge(u, v) for u, v in probes])\n",
    "  print(f\"- already edge: {a} ({a/n:.0%})\")\n",
    "  non_edges = set(nx.non_edges(graph))\n",
    "  ne = sum([np in non_edges for np in probes])\n",
    "  print(f\"- both nodes in graph: {ne} ({ne/n:.0%})\")\n",
    "  ng = sum([not (graph.has_node(u) and graph.has_node(v)) for u, v in probes])\n",
    "  print(f\"- not in graph: {ng} ({ng/n:.0%})\")\n",
    "def get_distances(graph: nx.Graph, cutoff: int = None) -> (List[NodePair], List[int]):\n",
    "  \"\"\"\n",
    "  Get all non-edges using BFS. When cutoff provided, consider only node pairs with at most this distance.\n",
    "  Returns:\n",
    "  - nodepairs: tuple containing all nodepairs\n",
    "  - distances: tuple containing all distances\n",
    "  \"\"\"\n",
    "  return zip(\n",
    "    *[\n",
    "      ((u, v), distance)\n",
    "      for u, (nbs_u, _) in tqdm(nx.all_pairs_dijkstra(graph, cutoff, weight=None), total=len(graph), desc=\"get_distances\")\n",
    "      for v, distance in nbs_u.items() if distance > 1 and (cutoff is None or distance <= cutoff) \n",
    "    ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T08:14:49.030419Z",
     "iopub.status.busy": "2020-08-30T08:14:49.030151Z",
     "iopub.status.idle": "2020-08-30T08:14:49.213202Z",
     "shell.execute_reply": "2020-08-30T08:14:49.212479Z",
     "shell.execute_reply.started": "2020-08-30T08:14:49.030388Z"
    }
   },
   "outputs": [],
   "source": [
    "edges = read_edges('out.topology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T08:15:06.397613Z",
     "iopub.status.busy": "2020-08-30T08:15:06.397271Z",
     "iopub.status.idle": "2020-08-30T08:15:06.401899Z",
     "shell.execute_reply": "2020-08-30T08:15:06.401100Z",
     "shell.execute_reply.started": "2020-08-30T08:15:06.397569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1.7e+05\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of {len(edges):.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T08:15:13.723829Z",
     "iopub.status.busy": "2020-08-30T08:15:13.723508Z",
     "iopub.status.idle": "2020-08-30T08:15:13.764820Z",
     "shell.execute_reply": "2020-08-30T08:15:13.764072Z",
     "shell.execute_reply.started": "2020-08-30T08:15:13.723796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-15 01:00:00\n",
      "2010-02-15 01:00:00\n",
      "no_selected_edges=67010, (3.9e-01)\n"
     ]
    }
   ],
   "source": [
    "edges_mature = filter_edgelist(edges, stop=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T08:15:14.000030Z",
     "iopub.status.busy": "2020-08-30T08:15:13.999895Z",
     "iopub.status.idle": "2020-08-30T08:15:14.020026Z",
     "shell.execute_reply": "2020-08-30T08:15:14.019486Z",
     "shell.execute_reply.started": "2020-08-30T08:15:14.000014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-15 01:00:01\n",
      "2010-02-15 01:07:33\n",
      "no_selected_edges=2992, (1.7e-02)\n"
     ]
    }
   ],
   "source": [
    "edges_probe = filter_edgelist(edges, start=50000, stop=70000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Choose here the parameters on how you want to define the learn and assessing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:03:24.004853Z",
     "iopub.status.busy": "2020-08-29T16:03:24.004705Z",
     "iopub.status.idle": "2020-08-29T16:03:24.590166Z",
     "shell.execute_reply": "2020-08-29T16:03:24.589659Z",
     "shell.execute_reply.started": "2020-08-29T16:03:24.004838Z"
    }
   },
   "outputs": [],
   "source": [
    "g_learn = giant_component(get_graph(edges_mature))\n",
    "uv_assessing = convert_to_set(edges_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:03:32.688013Z",
     "iopub.status.busy": "2020-08-29T16:03:32.687852Z",
     "iopub.status.idle": "2020-08-29T16:03:33.712757Z",
     "shell.execute_reply": "2020-08-29T16:03:33.712195Z",
     "shell.execute_reply.started": "2020-08-29T16:03:32.687997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random/probes.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(g_learn, 'random/graph.pkl', protocol=5)\n",
    "joblib.dump(uv_assessing, f'random/probes.pkl', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:03:34.433512Z",
     "iopub.status.busy": "2020-08-29T16:03:34.433283Z",
     "iopub.status.idle": "2020-08-29T16:06:00.388270Z",
     "shell.execute_reply": "2020-08-29T16:06:00.387691Z",
     "shell.execute_reply.started": "2020-08-29T16:03:34.433484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of probes: 19805\n",
      "- already edge: 117 (1%)\n",
      "- both nodes in graph: 5967 (30%)\n",
      "- not in graph: 8318 (42%)\n"
     ]
    }
   ],
   "source": [
    "report(graph=g_learn, probes=uv_assessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T07:25:12.679864Z",
     "iopub.status.busy": "2020-08-05T07:25:12.679699Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "targets = joblib.load(f'{folder}all/targets.pkl')\n",
    "nodepairs = joblib.load(f'{folder}all/nodepairs.pkl')\n",
    "distances = joblib.load(f'{folder}all/distances.pkl')\n",
    "g_learn = joblib.load(f'{folder}all/graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:06:00.389394Z",
     "iopub.status.busy": "2020-08-29T16:06:00.389235Z",
     "iopub.status.idle": "2020-08-29T16:06:18.091961Z",
     "shell.execute_reply": "2020-08-29T16:06:18.091033Z",
     "shell.execute_reply.started": "2020-08-29T16:06:00.389377Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_distances: 100%|██████████| 20981/20981 [00:13<00:00, 1582.25it/s]\n"
     ]
    }
   ],
   "source": [
    "nodepairs, _ = get_distances(g_learn, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:06:18.093358Z",
     "iopub.status.busy": "2020-08-29T16:06:18.093219Z",
     "iopub.status.idle": "2020-08-29T16:06:18.654218Z",
     "shell.execute_reply": "2020-08-29T16:06:18.653493Z",
     "shell.execute_reply.started": "2020-08-29T16:06:18.093341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1715286/1715286 [00:00<00:00, 3090986.12it/s]\n"
     ]
    }
   ],
   "source": [
    "targets = [nodepair in uv_assessing for nodepair in tqdm(nodepairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:06:18.655093Z",
     "iopub.status.busy": "2020-08-29T16:06:18.654974Z",
     "iopub.status.idle": "2020-08-29T16:06:31.517263Z",
     "shell.execute_reply": "2020-08-29T16:06:31.516783Z",
     "shell.execute_reply.started": "2020-08-29T16:06:18.655077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random/2/targets.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nodepairs, 'random/2/nodepairs.pkl', protocol=5)\n",
    "joblib.dump(targets, 'random/2/targets.pkl', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nodepairs = np.array(nodepairs)\n",
    "distances = np.array(distances)\n",
    "targets = np.array(targets)\n",
    "for select_distance in [3]:\n",
    "  print(select_distance)\n",
    "  filter_indices = (distances == select_distance)\n",
    "  nodepairs[filter_indices].dump(f'{folder}{select_distance}/nodepairs.pkl')\n",
    "  distances[filter_indices].dump(f'{folder}{select_distance}/distances.pkl')\n",
    "  targets[filter_indices].dump(f'{folder}{select_distance}/targets.pkl')\n",
    "  joblib.dump(g_learn, f'{folder}{select_distance}/graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T16:06:31.518137Z",
     "iopub.status.busy": "2020-08-29T16:06:31.518010Z",
     "iopub.status.idle": "2020-08-29T16:06:31.551312Z",
     "shell.execute_reply": "2020-08-29T16:06:31.550910Z",
     "shell.execute_reply.started": "2020-08-29T16:06:31.518121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.527109e-04\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(targets) / len(nodepairs):e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(distances=distances, targets=targets))\n",
    "df = df.groupby('distances')['targets'].agg(['size', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['size'], fill='tozeroy', name='# Nodepairs'))\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['sum'], fill='tozeroy', name='# Positives'))\n",
    "fig.update_layout(xaxis=dict(tickmode='linear', tick0=2, dtick=1), yaxis_type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['size'].cumsum(), fill='tozeroy', name='# Nodepairs'))\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['sum'].cumsum(), fill='tozeroy', name='# Positives'))\n",
    "fig.update_layout(xaxis=dict(tickmode='linear', tick0=2, dtick=1), yaxis_type=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = joblib.load(\"random/2/features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(df.corr(), x=df.columns, y=df.columns)\n",
    "fig.update_xaxes(side=\"top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot(df):\n",
    "  return sns.pairplot(\n",
    "    df[df['target']].append(df[~df['target']].sample(sum(df['target']))).apply(minmax_scale), \n",
    "    hue='target',\n",
    "    hue_order=[True, False],\n",
    "    palette={True: 'green', False: 'red'},\n",
    "    kind='reg',\n",
    "    diag_kws=dict(bw=.02),\n",
    "    plot_kws=dict(scatter_kws=dict(alpha=.1))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `parameter_optimalization.ipynb`. We choose the following parameters:\n",
    "- `max_depth = 1`\n",
    "- `tree_method = 'hist'`\n",
    "- `no feature scaling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T10:47:36.613131Z",
     "iopub.status.busy": "2020-08-13T10:47:36.612894Z",
     "iopub.status.idle": "2020-08-13T10:47:36.624712Z",
     "shell.execute_reply": "2020-08-13T10:47:36.624310Z",
     "shell.execute_reply.started": "2020-08-13T10:47:36.613110Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridsearch(df: pd.DataFrame, random_state=1, also_random=True, max_depth=[1, 2]) -> pd.DataFrame:\n",
    "  X = df.drop(columns='target').values\n",
    "  y = df['target'].values\n",
    "  \n",
    "  param_grid=dict(max_depth=max_depth, scale_pos_weight=[sum(~y)/sum(y), 1])\n",
    "  \n",
    "  X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3, random_state=random_state)\n",
    "  clf = XGBClassifier(random_state=random_state, tree_method='hist', n_jobs=6)\n",
    "  gridsearch = GridSearchCV(\n",
    "    clf, \n",
    "    param_grid=param_grid, \n",
    "    scoring='average_precision', \n",
    "    n_jobs=30,\n",
    "    cv=StratifiedKFold(shuffle=True, random_state=random_state),\n",
    "    return_train_score=True\n",
    "  )\n",
    "  \n",
    "  if also_random: \n",
    "    gridsearch_random = copy.deepcopy(gridsearch)\n",
    "    np.random.seed(random_state)\n",
    "    y_random = copy.deepcopy(y_trainval)\n",
    "    np.random.shuffle(y_random)\n",
    "  \n",
    "  gridsearch.fit(X_trainval, y_trainval)\n",
    "  df_dict = dict(\n",
    "      mean_train=gridsearch.cv_results_['mean_train_score'],\n",
    "      std_train=gridsearch.cv_results_['std_train_score'],\n",
    "      mean_test=gridsearch.cv_results_['mean_test_score'],\n",
    "      std_test=gridsearch.cv_results_['std_test_score'],\n",
    "      test_fold0=gridsearch.cv_results_[f'split0_test_score'],\n",
    "      test_fold1=gridsearch.cv_results_[f'split1_test_score'],\n",
    "      test_fold2=gridsearch.cv_results_[f'split2_test_score'],\n",
    "      test_fold3=gridsearch.cv_results_[f'split3_test_score'],\n",
    "      test_fold4=gridsearch.cv_results_[f'split4_test_score']\n",
    "  )\n",
    "  \n",
    "  if also_random: \n",
    "    gridsearch_random.fit(X_trainval, y_random)\n",
    "    df_dict['mean_train_random']=gridsearch_random.cv_results_['mean_train_score']\n",
    "    df_dict['std_train_random']=gridsearch_random.cv_results_['std_train_score']\n",
    "    df_dict['mean_test_random']=gridsearch_random.cv_results_['mean_test_score']\n",
    "    df_dict['std_test_random']=gridsearch_random.cv_results_['std_test_score']\n",
    "  df = pd.DataFrame(df_dict, index=pd.Index([(d['max_depth'], d['scale_pos_weight'] > 1) for d in gridsearch.cv_results_['params']], name=('max_depth', 'balanced')))\n",
    "  df['diff_train_test'] = (df['mean_test'] - df['mean_train']).abs()/df['mean_test']\n",
    "  df['rstd_test'] = df['std_test'] / df['mean_test']\n",
    "  if also_random: df['test_over_random'] = df['mean_test'] - df['mean_test_random']\n",
    "  return df.sort_values('mean_test', ascending=False)\n",
    "    \n",
    "def report_performance(df: pd.DataFrame, random_state=1, max_depth=1, tree_method='hist', balanced=True, n_jobs=128):\n",
    "  X = df.drop(columns='target').values\n",
    "  y = df['target'].values\n",
    "  X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3, random_state=random_state)\n",
    "  clf = XGBClassifier(max_depth=max_depth, n_jobs=128, tree_method=tree_method, scale_pos_weight=sum(~y)/sum(y) if balanced else 1 , random_state=random_state)\n",
    "  clf.fit(X_trainval, y_trainval)\n",
    "  y_pred = clf.predict_proba(X_test)[:,1]\n",
    "  return average_precision_score(y_test, y_pred), roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'temp/a1/2/features.pkl')\n",
    "X = df.drop(columns='target').values\n",
    "y = df['target'].values\n",
    "\n",
    "param_grid=dict(max_depth=[1, 2], scale_pos_weight=[sum(~y)/sum(y), 1])\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "clf = XGBClassifier(random_state=1, tree_method='hist', n_jobs=6)\n",
    "gridsearch = GridSearchCV(\n",
    "  clf, \n",
    "  param_grid=param_grid, \n",
    "  scoring='average_precision', \n",
    "  n_jobs=30,\n",
    "  cv=StratifiedKFold(shuffle=True, random_state=1),\n",
    "  return_train_score=True\n",
    ")\n",
    "gridsearch.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T10:47:44.433760Z",
     "iopub.status.busy": "2020-08-13T10:47:44.433532Z",
     "iopub.status.idle": "2020-08-13T10:47:49.592368Z",
     "shell.execute_reply": "2020-08-13T10:47:49.591702Z",
     "shell.execute_reply.started": "2020-08-13T10:47:44.433739Z"
    }
   },
   "outputs": [],
   "source": [
    "hps2 = gridsearch(pd.read_pickle(f'random/2/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T10:48:22.789687Z",
     "iopub.status.busy": "2020-08-13T10:48:22.789453Z",
     "iopub.status.idle": "2020-08-13T10:48:22.802639Z",
     "shell.execute_reply": "2020-08-13T10:48:22.802127Z",
     "shell.execute_reply.started": "2020-08-13T10:48:22.789666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_test</th>\n",
       "      <th>mean_train</th>\n",
       "      <th>diff_train_test</th>\n",
       "      <th>rstd_test</th>\n",
       "      <th>test_over_random</th>\n",
       "      <th>test_fold0</th>\n",
       "      <th>test_fold1</th>\n",
       "      <th>test_fold2</th>\n",
       "      <th>test_fold3</th>\n",
       "      <th>test_fold4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th>balanced</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>False</th>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.131076</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>0.039730</td>\n",
       "      <td>0.099973</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>0.122274</td>\n",
       "      <td>0.109967</td>\n",
       "      <td>0.114187</td>\n",
       "      <td>0.111323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.097232</td>\n",
       "      <td>0.104765</td>\n",
       "      <td>0.077468</td>\n",
       "      <td>0.042649</td>\n",
       "      <td>0.083471</td>\n",
       "      <td>0.093261</td>\n",
       "      <td>0.097869</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.092090</td>\n",
       "      <td>0.099541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>False</th>\n",
       "      <td>0.069166</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.073890</td>\n",
       "      <td>0.055839</td>\n",
       "      <td>0.064274</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.073122</td>\n",
       "      <td>0.062946</td>\n",
       "      <td>0.069090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.062651</td>\n",
       "      <td>0.063839</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.049290</td>\n",
       "      <td>0.059332</td>\n",
       "      <td>0.065601</td>\n",
       "      <td>0.067685</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.064136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean_test  mean_train  diff_train_test  rstd_test  \\\n",
       "max_depth balanced                                                      \n",
       "2         False      0.113700    0.131076         0.152823   0.039730   \n",
       "          True       0.097232    0.104765         0.077468   0.042649   \n",
       "1         False      0.069166    0.071592         0.035075   0.073890   \n",
       "          True       0.062651    0.063839         0.018969   0.065853   \n",
       "\n",
       "                    test_over_random  test_fold0  test_fold1  test_fold2  \\\n",
       "max_depth balanced                                                         \n",
       "2         False             0.099973    0.110750    0.122274    0.109967   \n",
       "          True              0.083471    0.093261    0.097869    0.103400   \n",
       "1         False             0.055839    0.064274    0.076400    0.073122   \n",
       "          True              0.049290    0.059332    0.065601    0.067685   \n",
       "\n",
       "                    test_fold3  test_fold4  \n",
       "max_depth balanced                          \n",
       "2         False       0.114187    0.111323  \n",
       "          True        0.092090    0.099541  \n",
       "1         False       0.062946    0.069090  \n",
       "          True        0.056500    0.064136  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps2[['mean_test', 'mean_train', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3 = gridsearch(pd.read_pickle(f'temp/a1/3/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps4 = gridsearch(pd.read_pickle(f'temp/a1/4/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps4[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T10:49:41.842868Z",
     "iopub.status.busy": "2020-08-13T10:49:41.842637Z",
     "iopub.status.idle": "2020-08-13T10:49:45.936638Z",
     "shell.execute_reply": "2020-08-13T10:49:45.935727Z",
     "shell.execute_reply.started": "2020-08-13T10:49:41.842847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06929365306164612, 0.7599842690910081)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_performance(pd.read_pickle(f'random/2/features.pkl'), max_depth=1, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(pd.read_pickle(f'temp/a1/3/features.pkl'), balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(pd.read_pickle(f'temp/a1/4/features.pkl'), balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
