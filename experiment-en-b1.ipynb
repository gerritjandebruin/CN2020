{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction in Condmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T09:17:06.936147Z",
     "iopub.status.busy": "2020-08-10T09:17:06.935945Z",
     "iopub.status.idle": "2020-08-10T09:17:08.015855Z",
     "shell.execute_reply": "2020-08-10T09:17:08.014962Z",
     "shell.execute_reply.started": "2020-08-10T09:17:06.936128Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import math\n",
    "from typing import List, Any, Dict, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Typing\n",
    "NodePair = Tuple[int, int]\n",
    "Edge = List[Tuple[int, int, Dict[str, datetime]]]\n",
    "\n",
    "folder = '/local/bruingjde/complexnetworks2020-experiment/temp/en-b1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T09:17:08.017068Z",
     "iopub.status.busy": "2020-08-10T09:17:08.016901Z",
     "iopub.status.idle": "2020-08-10T09:17:08.031265Z",
     "shell.execute_reply": "2020-08-10T09:17:08.030818Z",
     "shell.execute_reply.started": "2020-08-10T09:17:08.017049Z"
    }
   },
   "outputs": [],
   "source": [
    "def _filter_edgelist(edges: List[Edge], start, stop) -> List[Edge]: \n",
    "  \"\"\"Filter edgelist.  If start/ stop is float, start/stop from the fraction of total edges. If datetime, this is used.\"\"\" \n",
    "  no_edges = len(edges)\n",
    "  if start is None: start=0\n",
    "  if stop is None: stop=1\n",
    "  if type(start) is float or start == 0:\n",
    "    start_index = int(start*no_edges)\n",
    "    start = edges[start_index][2]['date']\n",
    "  if type(stop) is float or stop == 1:\n",
    "    stop_index = math.floor(stop*no_edges)-1\n",
    "    stop = edges[stop_index][2]['date']\n",
    "  return [edge for edge in edges if edge[2]['date'] >= start and edge[2]['date'] <= stop]\n",
    "def get_edgelist(file='src/enron.pkl', start=None, stop=None) -> List[Edge]:\n",
    "  return _filter_edgelist(joblib.load(file), start, stop)\n",
    "def giant_component(graph: nx.Graph) -> nx.Graph: return graph.subgraph(max(nx.connected_components(graph), key=len)).copy()\n",
    "def get_graph(edgelist: List[Edge]) -> nx.Graph:\n",
    "  \"\"\"Add edge to graph. Contains edge attribute weight.\"\"\"\n",
    "  g = nx.Graph()\n",
    "  \n",
    "  for u, v, _ in edgelist:\n",
    "    weight = g[u][v][\"weight\"]+1 if g.has_edge(u,v) else 1\n",
    "    g.add_edge(u, v, weight=weight)\n",
    "  \n",
    "  return g\n",
    "def report(graph:nx.Graph, probes: Tuple[int, int]):\n",
    "  n = len(probes)\n",
    "  print(f\"Number of probes: {n}\")\n",
    "  a = sum([graph.has_edge(u, v) for u, v in probes])\n",
    "  print(f\"- already edge: {a} ({a/n:.0%})\")\n",
    "  non_edges = set(nx.non_edges(graph))\n",
    "  ne = sum([np in non_edges for np in tqdm(probes)])\n",
    "  print(f\"- both nodes in graph: {ne} ({ne/n:.0%})\")\n",
    "  ng = sum([not (graph.has_node(u) and graph.has_node(v)) for u, v in tqdm(probes)])\n",
    "  print(f\"- not in graph: {ng} ({ng/n:.0%})\")\n",
    "def get_distances(graph: nx.Graph, cutoff: int = None) -> (List[NodePair], List[int]):\n",
    "  \"\"\"\n",
    "  Get all non-edges using BFS. When cutoff provided, consider only node pairs with at most this distance.\n",
    "  Returns:\n",
    "  - nodepairs: tuple containing all nodepairs\n",
    "  - distances: tuple containing all distances\n",
    "  \"\"\"\n",
    "  return zip(\n",
    "    *[\n",
    "      [(u, v), distance]\n",
    "      for u, (nbs_u, _) in tqdm(nx.all_pairs_dijkstra(graph, cutoff, weight=None), total=len(graph), desc=\"get_distances\")\n",
    "      for v, distance in nbs_u.items() if distance > 1 and (cutoff is None or distance <= cutoff) \n",
    "    ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Choose here the parameters on how you want to define the learn and assessing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T08:50:38.840244Z",
     "iopub.status.busy": "2020-08-10T08:50:38.839874Z",
     "iopub.status.idle": "2020-08-10T08:51:34.333971Z",
     "shell.execute_reply": "2020-08-10T08:51:34.332457Z",
     "shell.execute_reply.started": "2020-08-10T08:50:38.840205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172378/172378 [00:00<00:00, 1380696.25it/s]\n"
     ]
    }
   ],
   "source": [
    "g_train_matured = giant_component(get_graph(get_edgelist(stop=.7)))\n",
    "uv_train_probe = {(u, v) for u, v, _ in tqdm(get_edgelist(start=.7, stop=.85))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T08:54:46.930468Z",
     "iopub.status.busy": "2020-08-10T08:54:46.930290Z",
     "iopub.status.idle": "2020-08-10T08:54:52.480287Z",
     "shell.execute_reply": "2020-08-10T08:54:52.478940Z",
     "shell.execute_reply.started": "2020-08-10T08:54:46.930448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/local/bruingjde/complexnetworks2020-experiment/temp/en-b1/train/probes.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(g_train_matured, f'{folder}/train/graph.pkl')\n",
    "joblib.dump(uv_train_probe, f'{folder}/train/probes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(graph=g_train_matured, probes=uv_train_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T08:56:28.809748Z",
     "iopub.status.busy": "2020-08-10T08:56:28.809295Z",
     "iopub.status.idle": "2020-08-10T08:57:19.902587Z",
     "shell.execute_reply": "2020-08-10T08:57:19.901909Z",
     "shell.execute_reply.started": "2020-08-10T08:56:28.809702Z"
    }
   },
   "outputs": [],
   "source": [
    "g_test_matured = giant_component(get_graph(get_edgelist(stop=.85)))\n",
    "uv_test_probe = {(u, v) for u, v, _ in get_edgelist(start=.85)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(graph=g_test_matured, probes=uv_test_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T08:57:19.903667Z",
     "iopub.status.busy": "2020-08-10T08:57:19.903516Z",
     "iopub.status.idle": "2020-08-10T08:57:26.481715Z",
     "shell.execute_reply": "2020-08-10T08:57:26.480996Z",
     "shell.execute_reply.started": "2020-08-10T08:57:19.903648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/local/bruingjde/complexnetworks2020-experiment/temp/en-b1/test/probes.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(g_test_matured, f'{folder}/test/graph.pkl')\n",
    "joblib.dump(uv_test_probe, f'{folder}/test/probes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T09:17:12.312321Z",
     "iopub.status.busy": "2020-08-10T09:17:12.312114Z",
     "iopub.status.idle": "2020-08-10T09:17:14.558429Z",
     "shell.execute_reply": "2020-08-10T09:17:14.557872Z",
     "shell.execute_reply.started": "2020-08-10T09:17:12.312301Z"
    }
   },
   "outputs": [],
   "source": [
    "g_train_matured = joblib.load(f'{folder}/train/graph.pkl')\n",
    "uv_train_probe = joblib.load(f'{folder}/train/probes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T09:17:14.559438Z",
     "iopub.status.busy": "2020-08-10T09:17:14.559269Z",
     "iopub.status.idle": "2020-08-10T09:28:59.305897Z",
     "shell.execute_reply": "2020-08-10T09:28:59.305226Z",
     "shell.execute_reply.started": "2020-08-10T09:17:14.559417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_distances: 100%|██████████| 60313/60313 [11:02<00:00, 91.04it/s]  \n",
      "100%|██████████| 36686150/36686150 [00:10<00:00, 3532190.45it/s]\n"
     ]
    }
   ],
   "source": [
    "nodepairs_train, distances_train = get_distances(g_train_matured, cutoff=2)\n",
    "targets_train = [nodepair in uv_train_probe for nodepair in tqdm(nodepairs_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nodepairs = np.array(nodepairs)\n",
    "distances = np.array(distances)\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T09:29:29.365035Z",
     "iopub.status.busy": "2020-08-10T09:29:29.364770Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(nodepairs_train, f'{folder}/train/2/nodepairs.pkl')\n",
    "joblib.dump(distances_train, f'{folder}/train/2/distances.pkl')\n",
    "joblib.dump(targets_train, f'{folder}/train/2/targets.pkl')\n",
    "joblib.dump(g_train_matured, f'{folder}/train/2/graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(nodepairs, distances, targets, graph, path):\n",
    "  for select_distance in [2, 3, 4]:\n",
    "    print(select_distance)\n",
    "    filter_indices = (distances == select_distance)\n",
    "    for obj, filename in [(nodepairs, 'nodepairs'), (distances, 'distances'), (targets, 'targets')]:\n",
    "      obj[filter_indices].dump(f'{path}{select_distance}/{filename}.pkl')\n",
    "    joblib.dump(graph, f'{path}{select_distance}/graph.pkl')                         \n",
    "  print('all')\n",
    "  for obj, filename in [(nodepairs, 'nodepairs'), (distances, 'distances'), (targets, 'targets')]:\n",
    "    obj.dump(f'{path}all/{filename}.pkl')\n",
    "  joblib.dump(graph, f'{path}all/graph.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodepairs_test, distances_test = get_distances(g_test_matured)\n",
    "targets_test = [nodepair in uv_test_probe for nodepair in tqdm(nodepairs_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nodepairs_test = np.array(nodepairs_test)\n",
    "targets_test = np.array(targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{sum(targets_test) / len(nodepairs_test):e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df: pd.DataFrame): return df.drop(columns='target').values, df['target'].values\n",
    "def gridsearch(df: pd.DataFrame, random_state=1, also_random=True, max_depth=[1, 2]) -> pd.DataFrame:\n",
    "  X, y = get_x_y(df)\n",
    "  \n",
    "  \n",
    "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=random_state)\n",
    "  clf = XGBClassifier(random_state=random_state, tree_method='hist', n_jobs=6)\n",
    "  gridsearch = GridSearchCV(\n",
    "    clf, \n",
    "    param_grid=dict(max_depth=max_depth, scale_pos_weight=[sum(~y_train)/sum(y_train), 1]), \n",
    "    scoring='average_precision', \n",
    "    n_jobs=30,\n",
    "    cv=StratifiedKFold(shuffle=True, random_state=random_state),\n",
    "    return_train_score=True\n",
    "  )\n",
    "  \n",
    "  if also_random: \n",
    "    gridsearch_random = copy.deepcopy(gridsearch)\n",
    "    np.random.seed(random_state)\n",
    "    y_random = copy.deepcopy(y_train)\n",
    "    np.random.shuffle(y_random)\n",
    "  \n",
    "  gridsearch.fit(X_train, y_train)\n",
    "  df_dict = dict(\n",
    "      mean_train=gridsearch.cv_results_['mean_train_score'],\n",
    "      std_train=gridsearch.cv_results_['std_train_score'],\n",
    "      mean_val=gridsearch.cv_results_['mean_test_score'],\n",
    "      std_val=gridsearch.cv_results_['std_test_score'],\n",
    "      val_fold0=gridsearch.cv_results_[f'split0_test_score'],\n",
    "      val_fold1=gridsearch.cv_results_[f'split1_test_score'],\n",
    "      val_fold2=gridsearch.cv_results_[f'split2_test_score'],\n",
    "      val_fold3=gridsearch.cv_results_[f'split3_test_score'],\n",
    "      val_fold4=gridsearch.cv_results_[f'split4_test_score']\n",
    "  )\n",
    "  \n",
    "  if also_random: \n",
    "    gridsearch_random.fit(X_trainval, y_random)\n",
    "    df_dict['mean_train_random']=gridsearch_random.cv_results_['mean_train_score']\n",
    "    df_dict['std_train_random']=gridsearch_random.cv_results_['std_train_score']\n",
    "    df_dict['mean_val_random']=gridsearch_random.cv_results_['mean_test_score']\n",
    "    df_dict['std_val_random']=gridsearch_random.cv_results_['std_test_score']\n",
    "  df = pd.DataFrame(df_dict, index=pd.Index([(d['max_depth'], d['scale_pos_weight'] > 1) for d in gridsearch.cv_results_['params']], name=('max_depth', 'balanced')))\n",
    "  df['diff_train_val'] = df['mean_val'] - df['mean_train']\n",
    "  df['rstd_test'] = df['std_val'] / df['mean_val']\n",
    "  if also_random: df['val_over_random'] = df['mean_val'] - df['mean_val_random']\n",
    "  return df.sort_values('mean_val', ascending=False)\n",
    "    \n",
    "def report_performance(df_train: pd.DataFrame, df_test: pd.DataFrame, random_state=1, max_depth=1, tree_method='hist', balanced=True, n_jobs=128):\n",
    "  X, y = get_x_y(df_train)\n",
    "  clf = XGBClassifier(max_depth=max_depth, n_jobs=128, tree_method=tree_method, scale_pos_weight=sum(~y)/sum(y) if balanced else 1 , random_state=random_state)\n",
    "  clf.fit(X, y)\n",
    "  X_test, y_test = get_x_y(df_test)\n",
    "  y_pred = clf.predict_proba(X_test)[:,1]\n",
    "  return average_precision_score(y_test, y_pred), roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps2 = gridsearch(pd.read_pickle(f'temp/b1/train/2/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps2[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3 = gridsearch(pd.read_pickle(f'temp/b1/train/3/features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps4 = gridsearch(pd.read_pickle(f'temp/b1/train/4/features.pkl'), max_depth=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps4[['mean_test', 'diff_train_test', 'rstd_test', 'test_over_random', 'test_fold0', 'test_fold1', 'test_fold2', 'test_fold3', 'test_fold4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(df_train=pd.read_pickle(f'temp/b1/train/2/features.pkl'), df_test=pd.read_pickle(f'temp/b1/test/2/features.pkl'), balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(\n",
    "  df_train=pd.read_pickle(f'temp/b1/train/3/features.pkl')[pd.read_pickle(f'temp/b1/test/3/features.pkl').columns], \n",
    "  df_test=pd.read_pickle(f'temp/b1/test/3/features.pkl'), \n",
    "  balanced=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_performance(df_train=pd.read_pickle(f'temp/b1/train/4/features.pkl'), df_test=pd.read_pickle(f'temp/b1/test/4/features.pkl'), max_depth=2, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
